{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### big country&recyclable low_fats\n",
    "#### 多个条件的查找"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df [(condition_1 | codition_2)][columns_list]\n",
    "df [(condition_1 & codition_2)][columns_list]\n",
    "#什么茴香豆的n种写法；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### never order customer\n",
    "#### 两个表格之间 的 条件查找"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = customers[~customers['id'].isin(orders['customerId'])]\n",
    "# ~：逻辑非；\n",
    "#df[column].isin():判断是否在某一串数据中；\n",
    "#~isin():来判断不在其中；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### invalid tweet\n",
    "#### 针对字符串数据类型的条件判断以及各种操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[column_str].str.len()>len_target]\n",
    "#.str.len()\n",
    "\n",
    "###当在链式表达式中使用多个 Pandas .str 访问器方法时，\n",
    "#请确保在每个特定字符串函数之前使用 .str 访问器。\n",
    "#例如，users[\"name\"].str[1:].str.lower() 是正确的，而 users[\"name\"].str[1:].lower()\n",
    "\n",
    "#修改字符串中的大小写，也是茴香豆的n种写法了：\n",
    "users[\"name\"] = users[\"name\"].str[0].str.upper() + users[\"name\"].str[1:].str.lower()\n",
    "#取字符串的特定长度，再改大小写\n",
    "users[\"name\"] = users[\"name\"].str.title()\n",
    "#直接调用,保证首字母大写\n",
    "str.upper()        # 把所有字符中的小写字母转大写\n",
    "str.lower()         # 把所有字符中的大写字母转换成小写字母\n",
    "str.capitalize()    # 把字符串第一个字母转化为大写字母，其余小写（本题）\n",
    "str.title()          # 把每个单词的第一个字母转化为大写，其余小写 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### special bonus\n",
    "#### .apply()的应用，相当于写了个循环，根据行顺序遍历df对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(func, axis=0, raw=False, result_type=None, args=(), **kwargs)\n",
    "#func:应用的函数，可以是自定义的，或者lamda x:\n",
    "#axis:0(index) 根据行来操作，将行作为函数的输入，1（columns）将列作为函数的输入；\n",
    "#args:元祖，传递给函数的 额外参数；\n",
    "#kwargs:传递给函数的额外参数；\n",
    "# lamda x: (x 作为输入值)\n",
    "\n",
    "#针对这题的以‘M’作为开头的判断函数：\n",
    "df[column].startwith('m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### valid e-mail & specific disaster\n",
    "#### 正则表达式的字符串应用&str.等函数的应用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str.match()\n",
    "#是否完全对应某一字符串，再通过正则表达式来描述这一字符串；\n",
    "\"\"\"\"\n",
    "^：表示一个字符串或行的开头\n",
    "[a-z]：表示一个字符范围，匹配从 a 到 z 的任何字符。\n",
    "\n",
    "[0-9]：表示一个字符范围，匹配从 0 到 9 的任何字符。\n",
    "\n",
    "[a-zA-Z]：这个变量匹配从 a 到 z 或 A 到 Z 的任何字符。请注意，你可以在方括号内指定的字符范围的数量没有限制，您可以添加想要匹配的其他字符或范围。\n",
    "\n",
    "[^a-z]：这个变量匹配不在 a 到 z 范围内的任何字符。请注意，字符 ^ 用来否定字符范围，它在方括号内的含义与它的方括号外表示开始的含义不同。\n",
    "\n",
    "[a-z]*：表示一个字符范围，匹配从 a 到 z 的任何字符 0 次或多次。\n",
    "\n",
    "[a-z]+：表示一个字符范围，匹配从 a 到 z 的任何字符 1 次或多次。\n",
    "\n",
    ".：匹配任意一个字符。\n",
    "\n",
    "\\.：表示句点字符。请注意，反斜杠用于转义句点字符，因为句点字符在正则表达式中具有特殊含义。还要注意，在许多语言中，你需要转义反斜杠本身，因此需要使用\\\\.。\n",
    "\n",
    "$：表示一个字符串或行的结尾。\n",
    "\"\"\"\"\n",
    "\n",
    "str.contains('',regex=True)\n",
    "\"\"\"\"\n",
    "r\"(^|\\s)DIAB1\":^，字符串头；|：或；\\s:空格\n",
    "regex : default True,确认传入的是否为正则表达式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### highest salary employee for different department\n",
    "#### 如何实现*多个表格的连接(df.merge())*以及分组计数(df.groupby())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_1.merge(df_2, left_on='departmentId', right_on='id', how='left')\n",
    "#比connect更复杂的连接函数\n",
    "#how:'left' or 'right',保留哪个表的所用行；‘inner’or ‘outer’保留相同行或者所用行\n",
    "#on , right_on ,left_on: 选择各自表格中用于对其的列的数值\n",
    "#默认重复的列名后会增加“_x”,'_y'\n",
    "\n",
    "df_groupby = df.groupby()\n",
    "\"\"\"\"\n",
    "by:分组条件，可以是列名，列表or函数；\n",
    "groupby()返回一个DFgroupby对象需要结合 .mean(),.sunm() .count() \n",
    "#或者transform（‘max’）食用\n",
    "\"\"\"\"\n",
    "df_max = df.groupby('column').transform()\n",
    "\"\"\"\"\n",
    "transform（）对每一行应用，可以‘max’‘mean’，或者各种函数；\n",
    "最后返回一个与df长度相同的对象，或者直接赋值给原df对象的一个新列；\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rank scores\n",
    "#### 艹 ，竟然直接调用rank()解决，真是无所不能pandas；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rank(method = ,ascending = )\n",
    "# method：‘first’,'min','dense';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### count different salary types\n",
    "#### 这里主要学习了df的条件判断返回的值的格式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （1741）calculate time\n",
    "#### 还是groupby（）的应用，不过分组的依据变为两个变量了，先天后人"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （511）first_login\n",
    "#### 题解的groupby（）[].min()的效果要比自己想的先排序再去重的土办法好"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （2356）teacher & subject| (596) class with 5 stu\n",
    "#### 又学一个新函数（nunique()）罢了，先分组再用nunipue(),经典结构groupby(分组依据)[要的数据列].要执行的操作（求和，取平均，计算不重复元素数量）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".nunique()\n",
    "#统计非重复的元素个数\n",
    ".size()\n",
    "#统计分组的大小"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
